# `ai_engine/` ‚Äì Moteur IA + XAI

Ce dossier regroupe **le cerveau analytique** de TRUSTED AI SOC LITE :
extraction de features, scoring automatique, explication XAI et publication
des d√©cisions vers Wazuh / audit.

---

## 1. Structure

```
ai_engine/
‚îú‚îÄ‚îÄ analyse_scan.py        # Pipeline d'inf√©rence (lecture JSON ‚Üí score ‚Üí log)
‚îú‚îÄ‚îÄ feature_engineering.py # Fonctions de parsing + features partag√©es
‚îú‚îÄ‚îÄ train_model.py         # Entra√Ænement RandomForest sur des rapports √©tiquet√©s
‚îú‚îÄ‚îÄ requirements.txt       # D√©pendances IA/XAI (venv recommand√©)
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep           # `model.pkl` est g√©n√©r√© apr√®s entra√Ænement
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep           # `ia_events.log` & `last_features.json`
‚îî‚îÄ‚îÄ ../audit/              # `ia_decisions.json` (historique des verdicts)
```

> üí° Installez un environnement virtuel :
> ```bash
> cd /opt/trusted_ai_soc_lite/ai_engine
> python3 -m venv venv
> source venv/bin/activate
> pip install -r requirements.txt
> ```

---

## 2. Flux fonctionnel

1. `nmap_scanner/run_scan.sh` produit `reports/scan_xxx.json` via `parse_nmap.py`.
2. `analyse_scan.py` extrait les caract√©ristiques cl√©s :
   - nb de ports ouverts, services sensibles, CVE d√©tect√©es,
   - indices NSE (FTP anonyme, panneaux admin, etc.),
   - contexte OS et host.
3. Un mod√®le ML (`models/model.pkl`) est charg√©, sinon une heuristique prend le relais.
4. Pour chaque h√¥te :
   - calcul d'un `risk_score` (0‚Äì100) + `risk_level` (low/medium/high/critical),
   - g√©n√©ration d'une explication courte (`top_findings`).
5. L'√©v√©nement IA est journalis√© :
   - `logs/ia_events.log` (copie locale),
 - `/var/log/trusted_ai_soc_lite.log` (fichier surveill√© par le Wazuh Agent),
  - `../audit/ia_decisions.json` (historique structur√© pour reporting).

> ‚ÑπÔ∏è `nmap_scanner/run_scan.sh` appelle d√©sormais automatiquement `analyse_scan.py`. Exportez `AI_AUTORUN=0` si vous
> souhaitez lancer l'analyse manuellement ou personnalisez les chemins via `AI_ENGINE_DIR`, `AI_MODEL_PATH`,
> `AI_LOG_FILE`, `AI_WAZUH_LOG` et `AI_AUDIT_FILE`.

Exemple de payload :
```json
{
  "timestamp": "2025-11-17T11:30:00Z",
  "scan_id": "scan_2025-11-17_1130",
  "host": "192.168.1.10",
  "risk_score": 87,
  "risk_level": "critical",
  "top_findings": [
    "3 CVE d√©tect√©es",
    "2 services sensibles (FTP/SMB/etc.)",
    "FTP anonyme autoris√©"
  ]
}
```

---

## 3. Scripts principaux

### 3.1 `analyse_scan.py`

Commande type :
```bash
cd /opt/trusted_ai_soc_lite/ai_engine
python3 analyse_scan.py \
  ../nmap_scanner/reports/scan_2025-11-17_1130.json \
  --model models/model.pkl \
  --log-file logs/ia_events.log \
  --wazuh-log /var/log/trusted_ai_soc_lite.log \
  --audit-file ../audit/ia_decisions.json
```

Arguments utiles :
| Option | Description |
| --- | --- |
| `--model` | Mod√®le entra√Æn√© (joblib). S'il est absent, heuristique int√©gr√©e. |
| `--log-file` | Journal local des √©v√©nements IA. |
| `--wazuh-log` | Fichier suivi par le Wazuh Agent. D√©sactiver avec `--wazuh-log ""`. |
| `--audit-file` | Historique JSON pour reporting / Streamlit / pandas. |

Sorties :
- `logs/ia_events.log` : log JSON line par host.
- `logs/last_features.json` : features brutes pour debug/XAI.
- `../audit/ia_decisions.json` : liste d'√©v√©nements cumul√©s.

### 3.2 `feature_engineering.py`

- Normalise les donn√©es JSON issues de `parse_nmap.py`.
- Compile les scripts NSE (vulners, http-enum, ssh-brute, etc.).
- D√©tecte les CVE, services √† risque, indices d'authentification faible.
- Produit des `HostFeatures` pr√™ts √† √™tre consomm√©s par l'IA.

### 3.3 `train_model.py`

Permet d'entra√Æner rapidement un mod√®le RandomForest :
```bash
python3 train_model.py ../nmap_scanner/reports \
  --labels labels.json \
  --output models/model.pkl \
  --trees 300
```

Le fichier `labels.json` doit ressembler √† :
```json
[
  { "scan_id": "scan_2025-11-17_1130", "host": "192.168.1.10", "label": "critical" },
  { "host": "192.168.1.5", "label": "medium" }
]
```

Les labels accept√©s sont `low`, `medium`, `high`, `critical`.

---

## 4. Int√©gration Wazuh

1. Ajouter dans `/var/ossec/etc/ossec.conf` :
   ```xml
   <localfile>
     <log_format>json</log_format>
     <location>/var/log/trusted_ai_soc_lite.log</location>
   </localfile>
   ```
2. Cr√©er un decoder bas√© sur `risk_score` / `risk_level`.
3. D√©finir des r√®gles Wazuh :
   - `risk_level = critical` ‚Üí alerte niveau 12 + tag `AI_VULN_DETECTED`.
   - `risk_score > 80` ‚Üí d√©clencheur Active Response (UFW, mail, ticket).

---

## 5. Bonnes pratiques

- **Isolation** : utilisez `venv/` pour √©viter les conflits syst√®me.
- **Reproductibilit√©** : versionnez `models/model.pkl` uniquement s'il est anonymis√©.
- **Audit** : sauvegardez `ia_decisions.json` et `response_actions.json` pour vos rapports PFA.
- **Explainability** : branchez SHAP ou LIME sur `last_features.json` si vous devez d√©montrer la contribution des features.
- **Automatisation** : d√©clenchez `analyse_scan.py` depuis `run_scan.sh` ou un service `systemd` pour que chaque scan soit imm√©diatement scor√©.

---

## 6. Prochaines √©tapes possibles

- Ajouter SHAP/LIME pour g√©n√©rer des graphes d'explication.
- Exporter les scores vers un mini-dashboard (Streamlit / Grafana JSON).
- Int√©grer d'autres sources (syslog, vuln√©rateurs type OpenVAS) en convertissant leurs rapports vers le m√™me sch√©ma JSON.

